{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMP3359 proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 648,
     "status": "ok",
     "timestamp": 1587147774532,
     "user": {
      "displayName": "Yuyang Lin",
      "photoUrl": "",
      "userId": "11037694261943317117"
     },
     "user_tz": -480
    },
    "id": "AeIUlwdKpg5Y",
    "outputId": "e9cbf3f5-73a8-4850-97ba-4a7ff7565e58"
   },
   "outputs": [],
   "source": [
    "# this is optional (actually not necessary at all, who else will use google's laggy service)\n",
    "\n",
    "# \"\"\" Prepare Notebook for Google Colab \"\"\"\n",
    "# # Mount Google Drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# # Specify directory of course materials in Google Drive\n",
    "# module_dir = '/content/drive/My Drive/ai/proj/'\n",
    "\n",
    "# # Add course material directory in Google Drive to system path, for importing .py files later\n",
    "# # (Ref.: https://stackoverflow.com/questions/48905127/importing-py-files-in-google-colab)\n",
    "# import sys\n",
    "# sys.path.append(module_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3493,
     "status": "ok",
     "timestamp": 1587147780774,
     "user": {
      "displayName": "Yuyang Lin",
      "photoUrl": "",
      "userId": "11037694261943317117"
     },
     "user_tz": -480
    },
    "id": "Uu1ND_X_pQwH",
    "outputId": "6f674243-7479-4a34-852c-fc6db6d8d7d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /usr/local/lib/python3.7/site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/site-packages (from keras) (1.18.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/site-packages (from keras) (1.14.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/site-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/site-packages (from keras) (5.3.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/site-packages (from keras) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2787,
     "status": "ok",
     "timestamp": 1587147786052,
     "user": {
      "displayName": "Yuyang Lin",
      "photoUrl": "",
      "userId": "11037694261943317117"
     },
     "user_tz": -480
    },
    "id": "kK5tVs8RpQwO",
    "outputId": "1b877aee-28f4-45e0-ebd3-e9ac48aefd1f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LHCjxMj3pQwS"
   },
   "source": [
    "Load the train and test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JTYxa7qupQwT",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this is for google colab( DONOT RUN IT if working locally)\n",
    "\n",
    "# data_dir = os.path.join(module_dir, \"input/\")\n",
    "# data_path_train = os.path.join(data_dir, \"train.csv\")\n",
    "# data_path_test = os.path.join(data_dir, \"test.csv\")\n",
    "# data_path_test_label = os.path.join(data_dir, \"test_labels.csv\")\n",
    "# train = pd.read_csv(data_path_train)\n",
    "# test = pd.read_csv(data_path_test)\n",
    "# test_label = pd.read_csv(data_path_test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./input/train.csv')\n",
    "test = pd.read_csv('./input/test.csv')\n",
    "test_label = pd.read_csv('./input/test_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the data has the null input if so, do some data engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 732,
     "status": "ok",
     "timestamp": 1587148252305,
     "user": {
      "displayName": "Yuyang Lin",
      "photoUrl": "",
      "userId": "11037694261943317117"
     },
     "user_tz": -480
    },
    "id": "fYF50COQ2x0H",
    "outputId": "bd7cdd17-21f5-4e83-c205-fba85fb13aec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(id               False\n",
       " comment_text     False\n",
       " toxic            False\n",
       " severe_toxic     False\n",
       " obscene          False\n",
       " threat           False\n",
       " insult           False\n",
       " identity_hate    False\n",
       " dtype: bool,\n",
       " id              False\n",
       " comment_text    False\n",
       " dtype: bool)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().any(),test.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8W-xoZz0pQwY"
   },
   "outputs": [],
   "source": [
    "sen_train = train[\"comment_text\"]\n",
    "sen_test_temp = test[\"comment_text\"]\n",
    "\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "y_train = train[list_classes].values\n",
    "y_test_temp = test_label[list_classes].values\n",
    "\n",
    "sen_test = []\n",
    "y_test = []\n",
    "\n",
    "test_no = len(y_test_temp)\n",
    "for i in range(test_no):\n",
    "  if not np.array_equal(y_test_temp[i], [-1,-1,-1,-1,-1,-1]):\n",
    "    y_test.append(y_test_temp[i])\n",
    "    sen_test.append(sen_test_temp[i])\n",
    "    \n",
    "y_test = np.array(y_test)\n",
    "sen_test = np.array(sen_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rCyKJy_ZpQwd"
   },
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(sen_train))\n",
    "tokenized_train = tokenizer.texts_to_sequences(sen_train)\n",
    "tokenized_test = tokenizer.texts_to_sequences(sen_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 680,
     "status": "ok",
     "timestamp": 1587148312925,
     "user": {
      "displayName": "Yuyang Lin",
      "photoUrl": "",
      "userId": "11037694261943317117"
     },
     "user_tz": -480
    },
    "id": "2T9z0-0v3-FN",
    "outputId": "9f543992-558d-4027-f8e8-4e5950238985",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[688,\n",
       "  75,\n",
       "  1,\n",
       "  126,\n",
       "  130,\n",
       "  177,\n",
       "  29,\n",
       "  672,\n",
       "  4511,\n",
       "  12052,\n",
       "  1116,\n",
       "  86,\n",
       "  331,\n",
       "  51,\n",
       "  2278,\n",
       "  11448,\n",
       "  50,\n",
       "  6864,\n",
       "  15,\n",
       "  60,\n",
       "  2756,\n",
       "  148,\n",
       "  7,\n",
       "  2937,\n",
       "  34,\n",
       "  117,\n",
       "  1221,\n",
       "  15190,\n",
       "  2825,\n",
       "  4,\n",
       "  45,\n",
       "  59,\n",
       "  244,\n",
       "  1,\n",
       "  365,\n",
       "  31,\n",
       "  1,\n",
       "  38,\n",
       "  27,\n",
       "  143,\n",
       "  73,\n",
       "  3462,\n",
       "  89,\n",
       "  3085,\n",
       "  4583,\n",
       "  2273,\n",
       "  985]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenized_train[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kV6QiLqcpQwf"
   },
   "source": [
    "padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 878,
     "status": "ok",
     "timestamp": 1587148336644,
     "user": {
      "displayName": "Yuyang Lin",
      "photoUrl": "",
      "userId": "11037694261943317117"
     },
     "user_tz": -480
    },
    "id": "XcOn-q5ryHvh",
    "outputId": "3ff857a1-238a-4675-9177-a9e8dbe559c5"
   },
   "outputs": [],
   "source": [
    "# as usually DON'T RUN it in order to save your time\n",
    "totalNumWords = [len(one_comment) for one_comment in tokenized_train]\n",
    "plt.hist(totalNumWords,bins = np.arange(0,410,10))#[0,50,100,150,200,250,300,350,400])#,450,500,550,600,650,700,750,800,850,900])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TghmEOmDpQwg"
   },
   "outputs": [],
   "source": [
    "maxlen = 200\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "x_train = pad_sequences(tokenized_train, maxlen=maxlen)\n",
    "x_test = pad_sequences(tokenized_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KJ1X1gpPpQwi"
   },
   "source": [
    "build a simple modle with LSTM; Skipp the following when running other models as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BcDZsA3bpQwj"
   },
   "outputs": [],
   "source": [
    "inp = Input(shape=(maxlen,))\n",
    "embed_size = 128\n",
    "x = Embedding(max_features, embed_size)(inp)\n",
    "x = LSTM(60, return_sequences=True,name='lstm')(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(6, activation=\"sigmoid\")(\n",
    "    Dropout(0.1)(\n",
    "        Dense(50, activation=\"relu\")(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1794958,
     "status": "ok",
     "timestamp": 1587150215083,
     "user": {
      "displayName": "Yuyang Lin",
      "photoUrl": "",
      "userId": "11037694261943317117"
     },
     "user_tz": -480
    },
    "id": "AuZWH4TUpQwm",
    "outputId": "44c11946-86bf-41ef-8d28-ff35734e5ad9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_8 (Embedding)      (None, 200, 128)          2560000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 200, 60)           45360     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_8 (Glob (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 50)                3050      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 6)                 306       \n",
      "=================================================================\n",
      "Total params: 2,608,716\n",
      "Trainable params: 2,608,716\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 159571 samples, validate on 63978 samples\n",
      "Epoch 1/2\n",
      "159571/159571 [==============================] - 525s 3ms/step - loss: 0.0684 - accuracy: 0.9778 - val_loss: 0.0770 - val_accuracy: 0.9693\n",
      "Epoch 2/2\n",
      "159571/159571 [==============================] - 526s 3ms/step - loss: 0.0447 - accuracy: 0.9832 - val_loss: 0.0741 - val_accuracy: 0.9684\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=inp,outputs=x)\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "history = model.fit(x_train,y_train, batch_size=batch_size, epochs=epochs, validation_data=[x_test,y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DzRyUKBOnATC"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159571/159571 [==============================] - 89s 556us/step\n",
      "Training accuracy: 0.98535\n",
      "63978/63978 [==============================] - 36s 561us/step\n",
      "Testing Accuracy: 0.96839\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = model.evaluate(x_train,y_train)\n",
    "print(\"Training accuracy: {:.5f}\".format(accuracy))\n",
    "loss,accuracy = model.evaluate(x_test,y_test)\n",
    "print(\"Testing Accuracy: {:.5f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "159571/159571 [==============================] - 89s 556us/step\n",
    "Training accuracy: 0.98535\n",
    "63978/63978 [==============================] - 36s 561us/step\n",
    "Testing Accuracy: 0.96839"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 761,
     "status": "ok",
     "timestamp": 1587150292680,
     "user": {
      "displayName": "Yuyang Lin",
      "photoUrl": "",
      "userId": "11037694261943317117"
     },
     "user_tz": -480
    },
    "id": "LQQXbppJsuxN",
    "outputId": "ca613202-d140-4ad5-c758-5ec4adda5941",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" Visualize Training Results \"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Get training results\n",
    "history_dict = history.history\n",
    "train_acc = history_dict['accuracy']\n",
    "test_acc = history_dict['val_accuracy']\n",
    "\n",
    "# Plot training results\n",
    "plt.plot(train_acc, label='Train Acc.')\n",
    "plt.plot(test_acc, label='Test Acc.')\n",
    "\n",
    "# Show plot\n",
    "plt.title('Model Training Results(maxlen=200)')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Acc')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 859
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 719629,
     "status": "ok",
     "timestamp": 1587151037617,
     "user": {
      "displayName": "Yuyang Lin",
      "photoUrl": "",
      "userId": "11037694261943317117"
     },
     "user_tz": -480
    },
    "id": "qEnMqLuMHkzB",
    "outputId": "2ffe18e7-a5ec-4539-f29a-ebcb66989e2f"
   },
   "source": [
    "maxlen = 50\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "x_train = pad_sequences(tokenized_train, maxlen=maxlen)\n",
    "x_test = pad_sequences(tokenized_test, maxlen=maxlen)\n",
    "\n",
    "inp = Input(shape=(maxlen,))\n",
    "embed_size = 128\n",
    "x = Embedding(max_features, embed_size)(inp)\n",
    "x = LSTM(60, return_sequences=True,name='lstm')(x)\n",
    "x = GlobalMaxPool1D()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(6, activation=\"sigmoid\")(\n",
    "    Dropout(0.1)(\n",
    "        Dense(50, activation=\"relu\")(x)))\n",
    "\n",
    "model = Model(inputs=inp,outputs=x)\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "history = model.fit(x_train,y_train, batch_size=batch_size, epochs=epochs, validation_data=[x_test,y_test])\n",
    "\n",
    "\"\"\" Visualize Training Results \"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "### Get training results\n",
    "history_dict = history.history\n",
    "train_acc = history_dict['accuracy']\n",
    "test_acc = history_dict['val_accuracy']\n",
    "\n",
    "### Plot training results\n",
    "plt.plot(train_acc, label='Train Acc.')\n",
    "plt.plot(test_acc, label='Test Acc.')\n",
    "\n",
    "### Show plot\n",
    "plt.title('Model Training Results')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Acc')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###@Author Pu Hongxi\n",
    "<br><br>\n",
    "# Experiment with other models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.TextCNN\n",
    "According to the paper Convolutional Neural Networks for Sentence Classification by Yoon Kim, we can use word vector and use CNN as we do to images. The paper says CNN has excellent performance on sentence-level classification tasks with multiple benchmarks. So let's first give it a shoot and we will do some analysis once we have got the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing  is the same; Running the following when the padding is finished\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer, one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, Flatten, MaxPooling1D, Input, Concatenate\n",
    "from keras.models import load_model\n",
    "x_train;\n",
    "y_train;\n",
    "x_test;\n",
    "y_test;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 200, 128)          2560000   \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 198, 250)          96250     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_7 (Glob (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               32128     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 2,689,152\n",
      "Trainable params: 2,689,152\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 159571 samples, validate on 63978 samples\n",
      "Epoch 1/2\n",
      "159571/159571 [==============================] - 287s 2ms/step - loss: 0.0621 - accuracy: 0.9792 - val_loss: 0.0713 - val_accuracy: 0.9732\n",
      "Epoch 2/2\n",
      "159571/159571 [==============================] - 287s 2ms/step - loss: 0.0459 - accuracy: 0.9825 - val_loss: 0.0723 - val_accuracy: 0.9713\n"
     ]
    }
   ],
   "source": [
    "#CNN model\n",
    "#try to choose the same parameter as before so that we can compare the result with regards to the model choice\n",
    "#Parameters without specific comment are subject to fine-tuning.\n",
    "# the reason why I set them to numerical value is that I don't want to re-run to load the parameter value specified before\n",
    "emd_size = 128\n",
    "filters = 250\n",
    "kernal_size = 3 # normally is set to 3\n",
    "hidden_dims = 128\n",
    "vocab_size = 20000 # =max_features\n",
    "max_length = 200 # =maxlen\n",
    "epochs #2 It's better to change it to something larger say at least 5\n",
    "#but I don't want to waste time waiting so I will leave the training with larger epoch to my parter\n",
    "\n",
    "\n",
    "#As below is a shallow CNN; Definitely we can try with another deep CNN but it will take some time to fine-tuning as well hence\n",
    "# I will take care of that if I do have some spare time.\n",
    "# The reset is just routine with nothing worth mentioning.\n",
    "model_cnn = Sequential()\n",
    "model_cnn.add(Embedding(vocab_size, emd_size, input_length=max_length,))\n",
    "model_cnn.add(Conv1D(filters, kernal_size, activation='relu'))\n",
    "model_cnn.add(GlobalMaxPooling1D())\n",
    "model_cnn.add(Dense(hidden_dims,activation='relu'))\n",
    "model_cnn.add(Dropout(0.5))\n",
    "model_cnn.add(Dense(6,activation='sigmoid'))\n",
    "model_cnn.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model_cnn.summary()\n",
    "\n",
    "#Fit model\n",
    "history = model_cnn.fit(x_train,y_train, epochs=epochs,validation_data=(x_test,y_test),batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159571/159571 [==============================] - 27s 169us/step\n",
      "EMM! <manual Exclamation> That's the Training accuracy: 0.98581\n",
      "63978/63978 [==============================] - 11s 172us/step\n",
      "That's the one: Testing Accuracy: 0.97131\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = model_cnn.evaluate(x_train,y_train)\n",
    "print(\"EMM! <manual Exclamation> That's the Training accuracy: {:.5f}\".format(accuracy))\n",
    "loss,accuracy = model_cnn.evaluate(x_test,y_test)\n",
    "print(\"That's the one: Testing Accuracy: {:.5f}\".format(accuracy))\n",
    "\n",
    "#should I visualize it? No way for such fancy useless things. Do it yourself if you want.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "159571/159571 [==============================] - 27s 169us/step\n",
    "EMM! <manual Exclamation> That's the Training accuracy: 0.98581\n",
    "63978/63978 [==============================] - 11s 172us/step\n",
    "That's the one: Testing Accuracy: 0.97131\n",
    "\n",
    "    It has better performance than LSTM along"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.CNN + LSTM\n",
    "We have tried CNN and LSTM above, now let's implement them together to see the result. The motivation is that I want to see how it handles long sequences together with what to keep and what to forget.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, MaxPooling1D\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 200, 128)          2560000   \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 198, 250)          96250     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 99, 250)           0         \n",
      "=================================================================\n",
      "Total params: 2,656,250\n",
      "Trainable params: 2,656,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 200, 128)          2560000   \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 198, 250)          96250     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 99, 250)           0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 60)                74640     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               7808      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 2,739,472\n",
      "Trainable params: 2,739,472\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 159571 samples, validate on 63978 samples\n",
      "Epoch 1/2\n",
      "159571/159571 [==============================] - 488s 3ms/step - loss: 0.0604 - accuracy: 0.9799 - val_loss: 0.0748 - val_accuracy: 0.9707\n",
      "Epoch 2/2\n",
      "159571/159571 [==============================] - 486s 3ms/step - loss: 0.0451 - accuracy: 0.9830 - val_loss: 0.0778 - val_accuracy: 0.9689\n"
     ]
    }
   ],
   "source": [
    "#CNN model\n",
    "#try to choose the same parameter as before so that we can compare the result with regards to the model choice\n",
    "#Parameters without specific comment are subject to fine-tuning.\n",
    "# the reason why I set them to numerical value is that I don't want to re-run to load the parameter value specified before\n",
    "emd_size = 128\n",
    "filters = 250\n",
    "kernal_size = 3 # normally is set to 3\n",
    "hidden_dims = 128\n",
    "vocab_size = 20000 # =max_features\n",
    "max_length = 200 # =maxlen\n",
    "units=60\n",
    "epochs #2 It's better to change it to something larger say at least 5\n",
    "#but I don't want to waste time waiting so I will leave the training with larger epoch to my parter\n",
    "\n",
    "\n",
    "#As below is a shallow CNN; Definitely we can try with another deep CNN but it will take some time to fine-tuning as well hence\n",
    "# I will take care of that if I do have some spare time.\n",
    "# The reset is just routine with nothing worth mentioning.\n",
    "model_cnn_lstm = Sequential()\n",
    "model_cnn_lstm.add(Embedding(vocab_size, emd_size, input_length=max_length,))\n",
    "model_cnn_lstm.add(Conv1D(filters, kernal_size, activation='relu'))\n",
    "model_cnn_lstm.add(MaxPooling1D()) # also try 2D \n",
    "model_cnn_lstm.summary()\n",
    "model_cnn_lstm.add(LSTM(units=units)) #same as the above\n",
    "model_cnn_lstm.add(Dense(hidden_dims,activation='relu'))\n",
    "model_cnn_lstm.add(Dropout(0.5))\n",
    "model_cnn_lstm.add(Dense(6,activation='sigmoid'))\n",
    "model_cnn_lstm.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model_cnn_lstm.summary()\n",
    "\n",
    "#Fit model\n",
    "history = model_cnn_lstm.fit(x_train,y_train, epochs=epochs,validation_data=(x_test,y_test),batch_size=batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159571/159571 [==============================] - 93s 580us/step\n",
      "EMM! <manual Exclamation> That's the Training accuracy: 0.98529\n",
      "63978/63978 [==============================] - 38s 591us/step\n",
      "That's the one: Testing Accuracy: 0.96890\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = model_cnn_lstm.evaluate(x_train,y_train)\n",
    "print(\"EMM! <manual Exclamation> That's the Training accuracy: {:.5f}\".format(accuracy))\n",
    "loss,accuracy = model_cnn_lstm.evaluate(x_test,y_test)\n",
    "print(\"That's the one: Testing Accuracy: {:.5f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Till now, the test accuracy of various models is\n",
    "LSTM:  0.96839\n",
    "CNN:  0.97131\n",
    "CNN+ LSTM: 0.96890 \n",
    "\n",
    "IT's improved compared with the original one. \n",
    "As for why it's no better than CNN, I will let my parnter to find out by changing some parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.BiDirectional RNN(LSTM/GRU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need something that could remember previous information as well as remembering info for a long period of time.\n",
    "HA! That's the classical BiDirectional RNN.\n",
    "Here I only implemented it with LSTM, but in practice it could be done with GRU or both interchangably.\n",
    "I will leave it to my partner to do some test running,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_16 (Embedding)     (None, 200, 128)          2560000   \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 200, 60)           45360     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_9 (Glob (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               7808      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 2,613,942\n",
      "Trainable params: 2,613,942\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 159571 samples, validate on 63978 samples\n",
      "Epoch 1/2\n",
      "159571/159571 [==============================] - 510s 3ms/step - loss: 0.0662 - accuracy: 0.9783 - val_loss: 0.0748 - val_accuracy: 0.9693\n",
      "Epoch 2/2\n",
      "159571/159571 [==============================] - 516s 3ms/step - loss: 0.0448 - accuracy: 0.9832 - val_loss: 0.0681 - val_accuracy: 0.9721\n"
     ]
    }
   ],
   "source": [
    "model_BiD = Sequential()\n",
    "model_BiD.add(Embedding(vocab_size, emd_size, input_length=max_length,))\n",
    "model_BiD.add(LSTM(units=units,return_sequences = True))\n",
    "model_BiD.add(GlobalMaxPooling1D())\n",
    "model_BiD.add(Dense(hidden_dims,activation='relu'))\n",
    "model_BiD.add(Dropout(0.5))\n",
    "model_BiD.add(Dense(6,activation='sigmoid'))\n",
    "model_BiD.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model_BiD.summary()\n",
    "\n",
    "#Fit model\n",
    "history = model_BiD.fit(x_train,y_train, epochs=epochs,validation_data=(x_test,y_test),batch_size=batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159571/159571 [==============================] - 86s 539us/step\n",
      "Training accuracy: 0.98512\n",
      "63978/63978 [==============================] - 35s 553us/step\n",
      "Testing Accuracy: 0.97213\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = model_BiD.evaluate(x_train,y_train)\n",
    "print(\"Training accuracy: {:.5f}\".format(accuracy))\n",
    "loss,accuracy = model_BiD.evaluate(x_test,y_test)\n",
    "print(\"Testing Accuracy: {:.5f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Till now, the test accuracy of various models is\n",
    "LSTM:          0.96839\n",
    "CNN:           0.97131\n",
    "CNN+ LSTM:     0.96890 \n",
    "BiDir RNN:     0.97213\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Attention Models\n",
    "It's not covered in the lecture but since the release of Hierarchical Attention Networks for Document Classification paper written jointly by CMU and Microsoft guys in 2016, it's been quite popular.\n",
    "But what is the REAL incentive after trying this model?\n",
    "It's from the REAL TRUMP: \"what do you have to lose? I say, take it.\", so here I will give it a shoot as the president does to the hydroxychloroquine.\n",
    "\n",
    "As below is a simple attention model which help us by pay more attention to some word since toxic comments tend to be determined by just one or two toxic words, especially some 4 letter word, u know.\n",
    "\n",
    "Obviously, attention can be implemented together with models mentioned above, but since I don't have such time, I will leave it to my partner to do some trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/qqgeogor/keras-lstm-attention-glove840b-lb-0-043\n",
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(name='{}_W'.format(self.name),\n",
    "                                 shape=(input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight(name='{}_b'.format(self.name),\n",
    "                                     shape=(input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        # do not pass the mask to the next layers\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        e = K.reshape(K.dot(K.reshape(x, (-1, features_dim)), K.reshape(self.W, (features_dim, 1))), (-1, step_dim))  # e = K.dot(x, self.W)\n",
    "        if self.bias:\n",
    "            e += self.b\n",
    "        e = K.tanh(e)\n",
    "\n",
    "        a = K.exp(e)\n",
    "        # apply mask after the exp. will be re-normalized next\n",
    "        if mask is not None:\n",
    "            # cast the mask to floatX to avoid float64 upcasting in theano\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "        # in some cases especially in the early stages of training the sum may be almost zero\n",
    "        # and this results in NaN's. A workaround is to add a very small positive number  to the sum.\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "        a = K.expand_dims(a)\n",
    "\n",
    "        c = K.sum(a * x, axis=1)\n",
    "        return c\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], self.features_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer global_max_pooling1d_10: expected ndim=3, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-d5173b8fb7b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGlobalMaxPooling1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmodel_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_dims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer global_max_pooling1d_10: expected ndim=3, found ndim=2"
     ]
    }
   ],
   "source": [
    "\n",
    "model_a = Sequential()\n",
    "model_a.add(Embedding(vocab_size, emd_size, input_length=max_length,))\n",
    "model_a.add(LSTM(units=units,return_sequences = True))\n",
    "model_a.add(Attention(200))\n",
    "model_a.add(GlobalMaxPooling1D())\n",
    "model_a.add(Dense(hidden_dims,activation='relu'))\n",
    "model_a.add(Dropout(0.5))\n",
    "model_a.add(Dense(6,activation='sigmoid'))\n",
    "model_a.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model_a.summary()\n",
    "\n",
    "#Fit model\n",
    "history = model_a.fit(x_train,y_train, epochs=epochs,validation_data=(x_test,y_test),batch_size=batch_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also you can try different model layers, but to compare the result, I implemented the same layers.\n",
    "As below is another way to give it a shot, it's said to be 99% accuracy;\n",
    "https://www.kaggle.com/sanket30/cudnnlstm-lstm-99-accuracy\n",
    "You can dig in to find out why his model is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss,accuracy = model_a.evaluate(x_train,y_train)\n",
    "print(\"Training accuracy: {:.5f}\".format(accuracy))\n",
    "loss,accuracy = model_a.evaluate(x_test,y_test)\n",
    "print(\"Testing Accuracy: {:.5f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.BERT\n",
    "As mentioned in the comment, \"it's not difficult to implement BERT\",so BERT is not implemented. In addition, you may not want to download pretrained model which takes a while through streaming."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "comp3359proj.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
